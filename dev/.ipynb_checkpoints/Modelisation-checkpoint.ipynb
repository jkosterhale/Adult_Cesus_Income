{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 : Modelisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "import seaborn as sns\n",
    "import sklearn.metrics as metrics\n",
    "import sklearn.tree as tree\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SHARED_FOLDER = '../ressources/us_census_full'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open ('{}/train.csv'.format(SHARED_FOLDER), 'rb') as f:\n",
    "    train1 = pd.read_csv(f)\n",
    "\n",
    "with open ('{}/test.csv'.format(SHARED_FOLDER), 'rb') as f:\n",
    "    test1 = pd.read_csv(f)\n",
    "\n",
    "with open ('{}/train_cleaned.csv'.format(SHARED_FOLDER), 'rb') as f:\n",
    "    train = pd.read_csv(f)\n",
    "\n",
    "with open ('{}/test_cleaned.csv'.format(SHARED_FOLDER), 'rb') as f:\n",
    "    test = pd.read_csv(f)\n",
    "\n",
    "with open ('{}/train_income.csv'.format(SHARED_FOLDER), 'rb') as f:\n",
    "    train_income = pd.read_csv(f)\n",
    "    \n",
    "with open ('{}/test_income.csv'.format(SHARED_FOLDER), 'rb') as f:\n",
    "    target = pd.read_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del train['Unnamed: 0'] \n",
    "sns.heatmap(train.corr(), square=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmse_cv(model):\n",
    "    rmse= np.sqrt(-cross_val_score(model, X_train, y, scoring=\"neg_mean_squared_error\", cv = 5))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del train['Unnamed: 0'] \n",
    "del test['Unnamed: 0']\n",
    "del train_income['Unnamed: 0'] \n",
    "del target['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "income_df = pd.DataFrame(index = train.index, columns=[\"income\"])\n",
    "income_df[\"income\"] = train_income\n",
    "\n",
    "target_df = pd.DataFrame(index = test.index, columns=[\"income\"])\n",
    "target_df[\"income\"] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data = pd.concat((train.loc[:,'AAGE':'AHGA_Gr'], test.loc[:,'AAGE':'AHGA_Gr']))\n",
    "y = income_df.income\n",
    "X_train = all_data[:train.shape[0]]\n",
    "X_test = all_data[train.shape[0]:]\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Random Forest###########\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_jobs=-1)\n",
    "rfc.fit(X_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfc.predict(X_test1)\n",
    "cm = metrics.confusion_matrix(y_test1, y_pred)\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.subplot(2,1,1)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.ylabel(\"Real value\")\n",
    "plt.xlabel(\"Predicted value\")\n",
    "coefs = pd.Series(rfc.feature_importances_, index=X_train1.columns)\n",
    "coefs.sort()\n",
    "plt.subplot(2,1,2)\n",
    "coefs.plot(kind=\"bar\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfc.predict(X_test1)\n",
    "rfc_accuracy = accuracy_score(y_test1, y_pred, normalize=False)\n",
    "rfc_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####xgboost model##########\n",
    "import xgboost as xgb\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train1, label = y_train1)\n",
    "dtest = xgb.DMatrix(X_test1, label = y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###for rmse , pour avoir the best num_boost_round(where it stops)\n",
    "param = {'bst:max_depth':4, 'bst:eta':0.1}\n",
    "cv_xgb = xgb.cv(param, dtrain,  num_boost_round=8000, early_stopping_rounds=1000)\n",
    "cv_xgb[[\"test-rmse-mean\", \"train-rmse-mean\"]].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###That's for fixing paremeters of model but I cannot finish it in my ordi cause the function of GridSearchCV need much \n",
    "##time and it needs to do the same thing for every paremeter. \n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "\n",
    "param_test1 = {\n",
    " 'max_depth':[3,4,5,6,7,8,9],\n",
    " 'min_child_weight':[1,3,5,6]\n",
    "}\n",
    "\n",
    "gsearch1 = GridSearchCV(estimator = XGBRegressor( learning_rate =0.1, n_estimators=54, max_depth=4, min_child_weight=1, \n",
    "                                                 gamma=0, subsample=0.8, colsample_bytree=0.8, objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27),\n",
    "                        param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch1.fit(X_train, y)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###scikit-learn API#####\n",
    "#model_xgb = xgb.XGBClassifier()\n",
    "model_xgb = xgb.XGBClassifier(colsample_bytree=0.2, gamma=0.0, max_depth=4, min_child_weight=1.5, learning_rate=0.01, reg_alpha=0.9, \n",
    "                            reg_lambda=0.6, subsample=0.2, seed=42, silent=True, objective='binary:logistic', n_estimators = 7200)\n",
    "model_xgb.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_xgb.predict(X_test1)\n",
    "cm = metrics.confusion_matrix(y_test1, y_pred)\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.subplot(2,1,1)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.ylabel(\"Real value\")\n",
    "plt.xlabel(\"Predicted value\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "xgb_accuracy = accuracy_score(y_test1, y_pred, normalize=False)\n",
    "xgb_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############Plot features importance of XGB#######################\n",
    "plt.figure(figsize=(10, 5))\n",
    "xgb.plot_importance(model_xgb,max_num_features=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######Logistic Regression###########\n",
    "import sklearn.linear_model as linear_model\n",
    "cls = linear_model.LogisticRegression()\n",
    "cls.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cls.predict(X_test1)\n",
    "cm = metrics.confusion_matrix(y_test1, y_pred)\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.subplot(2,1,1)\n",
    "#sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=1, yticklabels=1)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.ylabel(\"Real value\")\n",
    "plt.xlabel(\"Predicted value\")\n",
    "coefs = pd.Series(cls.coef_[0], index=X_train1.columns)\n",
    "coefs.sort()\n",
    "plt.subplot(2,1,2)\n",
    "coefs.plot(kind=\"bar\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cls.predict(X_test1)\n",
    "cls_accuracy = accuracy_score(y_test1, y_pred, normalize=False)\n",
    "cls_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Accuracy#######\n",
    "columns = ['accuracy']\n",
    "index = ['cls','rfc', 'xgb']\n",
    "df = pd.DataFrame(index = index, columns = columns)\n",
    "df['accuracy'].loc['cls'] = cls_accuracy\n",
    "df['accuracy'].loc['rfc'] = rfc_accuracy\n",
    "df['accuracy'].loc['xgb'] = xgb_accuracy\n",
    "df.plot(kind=\"bar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Prediction######\n",
    "target = target_df.income\n",
    "target_pred = model_xgb.predict(X_test)\n",
    "cm = metrics.confusion_matrix(target, target_pred)\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.subplot(2,1,1)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.ylabel(\"Real value\")\n",
    "plt.xlabel(\"Predicted value\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
