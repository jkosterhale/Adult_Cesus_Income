{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 : Modelisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuase the lack of work in the last two step, the result of modeling is not good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SHARED_FOLDER = '../ressources/us_census_full'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open ('{}/train.csv'.format(SHARED_FOLDER), 'rb') as f:\n",
    "    train1 = pd.read_csv(f)\n",
    "\n",
    "with open ('{}/test.csv'.format(SHARED_FOLDER), 'rb') as f:\n",
    "    test1 = pd.read_csv(f)\n",
    "\n",
    "with open ('{}/train_cleaned.csv'.format(SHARED_FOLDER), 'rb') as f:\n",
    "    train = pd.read_csv(f)\n",
    "\n",
    "with open ('{}/test_cleaned.csv'.format(SHARED_FOLDER), 'rb') as f:\n",
    "    test = pd.read_csv(f)\n",
    "\n",
    "with open ('{}/train_income.csv'.format(SHARED_FOLDER), 'rb') as f:\n",
    "    train_income = pd.read_csv(f)\n",
    "    \n",
    "with open ('{}/test_income.csv'.format(SHARED_FOLDER), 'rb') as f:\n",
    "    target = pd.read_csv(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I don't think that the correlation means that variable has a strong influence in the predictive target because it also depends on the model that we choose so I didn't plot the correlation between variable and the income level. But from the correlation between different variable, we can find like WKSWORK has  a strong correlation with NOEMP so maybe we can delete either but I think it will need more analysis and I'm not sure that's necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train['Unnamed: 0'] \n",
    "sns.heatmap(train.corr(), square=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmse_cv(model):\n",
    "    rmse= np.sqrt(-cross_val_score(model, X_train, y, scoring=\"neg_mean_squared_error\", cv = 5))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del train['Unnamed: 0'] \n",
    "del test['Unnamed: 0'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "income_df = pd.DataFrame(index = train.index, columns=[\"income\"])\n",
    "income_df[\"income\"] = train_income\n",
    "\n",
    "target_df = pd.DataFrame(index = test.index, columns=[\"income\"])\n",
    "target_df[\"income\"] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data = pd.concat((train.loc[:,'AAGE':'AHGA_Gr'], test.loc[:,'AAGE':'AHGA_Gr']))\n",
    "y = income_df.income\n",
    "X_train = all_data[:train.shape[0]]\n",
    "X_test = all_data[train.shape[0]:]\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####Random Forest###########\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_jobs=-1)\n",
    "rfc.fit(X_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####xgboost model##########\n",
    "import xgboost as xgb\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train1, label = y_train1)\n",
    "dtest = xgb.DMatrix(X_test1, label = y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###for rmse , pour avoir the best num_boost_round(where it stops)\n",
    "param = {'bst:max_depth':4, 'bst:eta':0.1}\n",
    "cv_xgb = xgb.cv(param, dtrain,  num_boost_round=8000, early_stopping_rounds=1000)\n",
    "cv_xgb[[\"test-rmse-mean\", \"train-rmse-mean\"]].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###That's for fixing paremeters of model but I cannot finish it in my ordi cause the function of GridSearchCV need much \n",
    "##time and it needs to do the same thing for every paremeter. \n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "\n",
    "param_test1 = {\n",
    " 'max_depth':[3,4,5,6,7,8,9],\n",
    " 'min_child_weight':[1,3,5,6]\n",
    "}\n",
    "\n",
    "gsearch1 = GridSearchCV(estimator = XGBRegressor( learning_rate =0.1, n_estimators=54, max_depth=4, min_child_weight=1, \n",
    "                                                 gamma=0, subsample=0.8, colsample_bytree=0.8, objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27),\n",
    "                        param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch1.fit(X_train, y)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###scikit-learn API#####\n",
    "model_xgb = xgb.XGBClassifier()\n",
    "model_xgb.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_xgb = pd.DataFrame({\"preds\":model_xgb.predict(X_test1), \"true\":y_test1})\n",
    "preds_xgb[\"residuals\"] = preds_xgb[\"true\"] - preds_xgb[\"preds\"] \n",
    "preds_xgb[\"residuals\"].abs().mean() \n",
    "preds_xgb.plot(x = \"preds\", y = \"residuals\",kind = \"scatter\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(y_test1, preds_xgb[\"preds\"], s=20)\n",
    "plt.title('Predicted vs. Actual')\n",
    "plt.xlabel('Actual Sale Price')\n",
    "plt.ylabel('Predicted Sale Price')\n",
    "plt.plot([min(y_test1), max(y_test1)], [min(y_test1), max(y_test1)])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In fact in the first time, I want to try the LogisticRegression with the code as below but the ordi always block "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.linear_model as linear_model\n",
    "cls = linear_model.LogisticRegression()\n",
    "cls.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = cls.predict(X_test1)\n",
    "cm = metrics.confusion_matrix(y_test1, y_pred)\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.subplot(2,1,1)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=target_df[\"income\"].classes_, yticklabels=target_df[\"income\"].classes_)\n",
    "plt.ylabel(\"Real value\")\n",
    "plt.xlabel(\"Predicted value\")\n",
    "print \"F1 score: %f\" % skl.metrics.f1_score(y_test1, y_pred)\n",
    "coefs = pd.Series(cls.coef_[0], index=X_train1.columns)\n",
    "coefs.sort()\n",
    "plt.subplot(2,1,2)\n",
    "coefs.plot(kind=\"bar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for logit regression. \n",
    "# statsmodel is chosen because it outputs descriptive stats for the model\n",
    "import statsmodels.api as sm\n",
    "\n",
    "logit_train = sm.Logit(y_train1, X_train1) \n",
    "result_train = logit_train.fit()\n",
    "\n",
    "y_test_pred = result_train.predict(X_test1) \n",
    "y_test_pred = (y_test_pred > 0.5).astype(int) \n",
    "acc = accuracy_score(y_test1, y_test_pred)\n",
    "auc = roc_auc_score(y_test1, y_test_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
